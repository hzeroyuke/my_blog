
## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
2. [å·¥ä½œæµç¨‹](#å·¥ä½œæµç¨‹)
3. [DeepSeek V3.1 å®Œæ•´ç¤ºä¾‹](#deepseek-v31-å®Œæ•´ç¤ºä¾‹)
4. [Llama 3.1 å®Œæ•´ç¤ºä¾‹](#llama-31-å®Œæ•´ç¤ºä¾‹)
5. [ä¸¤è€…å¯¹æ¯”](#ä¸¤è€…å¯¹æ¯”)
6. [æºç è§£æ](#æºç è§£æ)
7. [å®æˆ˜æŒ‡å—](#å®æˆ˜æŒ‡å—)

---

## æ ¸å¿ƒæ¦‚å¿µ

### â“ é—®é¢˜ï¼šä¸ºä»€ä¹ˆéœ€è¦ vLLM çš„ Tool Calling æœºåˆ¶ï¼Ÿ

å¾ˆå¤šæ¨¡å‹ï¼ˆå¦‚ DeepSeek V3.1ã€Llama 3.1ï¼‰çš„**åŸç”Ÿ `chat_template` å¹¶ä¸æ”¯æŒå¤„ç† `tools` å‚æ•°**ã€‚å³ä½¿æ¨¡å‹åœ¨é¢„è®­ç»ƒæ—¶å­¦ä¼šäº† function calling çš„æ ¼å¼ï¼ˆspecial tokensï¼‰ï¼Œtokenizer çš„æ¨¡æ¿ä¹Ÿæ— æ³•è‡ªåŠ¨å°†å·¥å…·æè¿°æ³¨å…¥åˆ° prompt ä¸­ã€‚

### âœ… vLLM çš„è§£å†³æ–¹æ¡ˆ

vLLM é€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶å®ç°å®Œæ•´çš„ tool calling æ”¯æŒï¼š

1. **è‡ªå®šä¹‰ Chat Template** - è´Ÿè´£å°†å·¥å…·æè¿°æ³¨å…¥åˆ° prompt
2. **ToolParser** - è´Ÿè´£è§£ææ¨¡å‹è¾“å‡ºä¸­çš„å·¥å…·è°ƒç”¨
3. **æœåŠ¡å±‚é›†æˆ** - å°†ä¸Šè¿°ç»„ä»¶æ— ç¼æ•´åˆåˆ° OpenAI å…¼å®¹çš„ API ä¸­

---

## å·¥ä½œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ç”¨æˆ·è¯·æ±‚ï¼ˆå« messages + toolsï¼‰                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. vLLM æœåŠ¡å±‚                                                    â”‚
â”‚    - é€‰æ‹©å¯¹åº”çš„ chat_templateï¼ˆdeepseekv31.jinja/llama3.1.jinjaï¼‰â”‚
â”‚    - è°ƒç”¨ apply_chat_template(messages, tools=tools)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Chat Template å¤„ç†                                             â”‚
â”‚    - æ£€æµ‹åˆ° tools å‚æ•°ä¸ä¸ºç©º                                      â”‚
â”‚    - å°†å·¥å…·æè¿°æ ¼å¼åŒ–å¹¶æ³¨å…¥åˆ° system_prompt                        â”‚
â”‚    - æ‹¼æ¥å®Œæ•´çš„ promptï¼ˆå«å·¥å…·å®šä¹‰ + ç”¨æˆ·æ¶ˆæ¯ï¼‰                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. æ¨¡å‹æ¨ç†                                                       â”‚
â”‚    - æ¥æ”¶å®Œæ•´ promptï¼ˆå·²åŒ…å«å·¥å…·æè¿°ï¼‰                             â”‚
â”‚    - ç”Ÿæˆè¾“å‡ºï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ—¶å­¦ä¹ çš„ special tokensï¼‰                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ToolParser è§£æ                                                â”‚
â”‚    - DeepSeekV31ToolParser: è§£æ <ï½œtoolâ–callâ–beginï½œ>... æ ¼å¼   â”‚
â”‚    - Llama3JsonToolParser: è§£æ {"name": "...", "parameters"...} â”‚
â”‚    - æå–ç»“æ„åŒ–çš„å·¥å…·è°ƒç”¨ä¿¡æ¯                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. è¿”å›ç»™ç”¨æˆ·                                                     â”‚
â”‚    - æ ‡å‡† OpenAI æ ¼å¼çš„ tool_calls                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DeepSeek V3.1 å®Œæ•´ç¤ºä¾‹

### 1. ç”¨æˆ·è¯·æ±‚

```python
import requests

url = "http://localhost:8000/v1/chat/completions"
payload = {
    "model": "deepseek-ai/DeepSeek-V3.1",
    "messages": [
        {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
    ],
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {
                            "type": "string",
                            "description": "åŸå¸‚åç§°"
                        },
                        "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"],
                            "description": "æ¸©åº¦å•ä½"
                        }
                    },
                    "required": ["city"]
                }
            }
        }
    ],
    "tool_choice": "auto"
}

response = requests.post(url, json=payload)
print(response.json())
```

### 2. Chat Template å¤„ç†

**æ–‡ä»¶**: `examples/tool_chat_template_deepseekv31.jinja`

**å…³é”®ä»£ç **ï¼ˆç¬¬ 19-26 è¡Œï¼‰ï¼š

```jinja2
{% if tools is defined and tools is not none %}
  {% set tool_ns = namespace(text='## Tools\nYou have access to the following tools:\n') %}
  {% for tool in tools %}
    {% set tool_ns.text = tool_ns.text + '\n### ' + tool.function.name +
         '\nDescription: ' + tool.function.description +
         '\n\nParameters: ' + (tool.function.parameters | tojson) + '\n' %}
  {% endfor %}
  {% set tool_ns.text = tool_ns.text +
       "\nIMPORTANT: ALWAYS adhere to this exact format for tool use:\n" +
       "<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>tool_call_name<ï½œtoolâ–sepï½œ>" +
       "tool_call_arguments<ï½œtoolâ–callâ–endï½œ><ï½œtoolâ–callsâ–endï½œ>\n..." %}

  {% set ns.system_prompt = ns.system_prompt + '\n\n' + tool_ns.text %}
{% endif %}
```

**ç”Ÿæˆçš„å·¥å…·æè¿°**ï¼ˆæ³¨å…¥åˆ° system_promptï¼‰ï¼š

```
## Tools
You have access to the following tools:

### get_weather
Description: è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

Parameters: {"type":"object","properties":{"city":{"type":"string","description":"åŸå¸‚åç§°"},"unit":{"type":"string","enum":["celsius","fahrenheit"],"description":"æ¸©åº¦å•ä½"}},"required":["city"]}

IMPORTANT: ALWAYS adhere to this exact format for tool use:
<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>tool_call_name<ï½œtoolâ–sepï½œ>tool_call_arguments<ï½œtoolâ–callâ–endï½œ><ï½œtoolâ–callsâ–endï½œ>

Where:

- `tool_call_name` must be an exact match to one of the available tools
- `tool_call_arguments` must be valid JSON that strictly follows the tool's Parameters Schema
- For multiple tool calls, chain them directly without separators or spaces
```

### 3. å®Œæ•´ Promptï¼ˆå‘é€ç»™æ¨¡å‹ï¼‰

```
<ï½œbeginâ–ofâ–sentenceï½œ>## Tools
You have access to the following tools:

### get_weather
Description: è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

Parameters: {"type":"object","properties":{"city":{"type":"string","description":"åŸå¸‚åç§°"},"unit":{"type":"string","enum":["celsius","fahrenheit"],"description":"æ¸©åº¦å•ä½"}},"required":["city"]}

IMPORTANT: ALWAYS adhere to this exact format for tool use:
<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>tool_call_name<ï½œtoolâ–sepï½œ>tool_call_arguments<ï½œtoolâ–callâ–endï½œ><ï½œtoolâ–callsâ–endï½œ>

<ï½œUserï½œ>åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ<ï½œAssistantï½œ></think>
```

### 4. æ¨¡å‹è¾“å‡º

```
<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>get_weather<ï½œtoolâ–sepï½œ>{"city":"åŒ—äº¬","unit":"celsius"}<ï½œtoolâ–callâ–endï½œ><ï½œtoolâ–callsâ–endï½œ><ï½œendâ–ofâ–sentenceï½œ>
```

### 5. ToolParser è§£æ

**æ–‡ä»¶**: `vllm/entrypoints/openai/tool_parsers/deepseekv31_tool_parser.py`

**å…³é”®ä»£ç **ï¼ˆç¬¬ 78-120 è¡Œï¼‰ï¼š

```python
def extract_tool_calls(self, model_output: str, request) -> ExtractedToolCallInformation:
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨æ ‡è®°
    if self.tool_calls_start_token not in model_output:
        return ExtractedToolCallInformation(
            tools_called=False, tool_calls=[], content=model_output
        )

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å·¥å…·è°ƒç”¨
    # æ­£åˆ™: <ï½œtoolâ–callâ–beginï½œ>(?P<function_name>.*?)<ï½œtoolâ–sepï½œ>(?P<function_arguments>.*?)<ï½œtoolâ–callâ–endï½œ>
    function_call_tuples = self.tool_call_regex.findall(model_output)

    tool_calls = []
    for match in function_call_tuples:
        function_name, function_args = match
        tool_calls.append(
            ToolCall(
                type="function",
                function=FunctionCall(
                    name=function_name,
                    arguments=function_args  # ä¿æŒä¸º JSON å­—ç¬¦ä¸²
                ),
            )
        )

    # æå–å·¥å…·è°ƒç”¨å‰çš„æ–‡æœ¬å†…å®¹
    content = model_output[:model_output.find(self.tool_calls_start_token)]

    return ExtractedToolCallInformation(
        tools_called=True,
        tool_calls=tool_calls,
        content=content if content else None,
    )
```

**è§£æç»“æœ**ï¼š

```python
ExtractedToolCallInformation(
    tools_called=True,
    tool_calls=[
        ToolCall(
            type="function",
            function=FunctionCall(
                name="get_weather",
                arguments='{"city":"åŒ—äº¬","unit":"celsius"}'
            )
        )
    ],
    content=None
)
```

### 6. è¿”å›ç»™ç”¨æˆ·ï¼ˆOpenAI æ ¼å¼ï¼‰

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "deepseek-ai/DeepSeek-V3.1",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"city\":\"åŒ—äº¬\",\"unit\":\"celsius\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ]
}
```

---

## Llama 3.1 å®Œæ•´ç¤ºä¾‹

### 1. ç”¨æˆ·è¯·æ±‚

```python
payload = {
    "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "messages": [
        {"role": "user", "content": "What's the weather like in San Francisco?"}
    ],
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get the current weather for a city",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {"type": "string"},
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                    },
                    "required": ["city"]
                }
            }
        }
    ]
}
```

### 2. Chat Template å¤„ç†

**æ–‡ä»¶**: `examples/tool_chat_template_llama3.1_json.jinja`

**å…³é”®ä»£ç **ï¼ˆç¬¬ 56-77 è¡Œï¼‰ï¼š

```jinja2
{%- if tools_in_user_message and not tools is none %}
    {#- æå–ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ #}
    {%- if messages[0]['content'] is string %}
        {%- set first_user_message = messages[0]['content']|trim %}
    {%- else %}
        {%- set first_user_message = messages[0]['content'] | selectattr('type', 'equalto', 'text') | map(attribute='text') | map('trim') | join('\n') %}
    {%- endif %}
    {%- set messages = messages[1:] %}

    {{- '<|start_header_id|>user<|end_header_id|>\n\n' -}}
    {{- "Given the following functions, please respond with a JSON for a function call " }}
    {{- "with its proper arguments that best answers the given prompt.\n\n" }}
    {{- 'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}. ' }}
    {{- "Do not use variables.\n\n" }}
    {%- for t in tools %}
        {{- t | tojson(indent=4) }}
        {{- "\n\n" }}
    {%- endfor %}
    {{- first_user_message + "<|eot_id|>"}}
{%- endif %}
```

**ç”Ÿæˆçš„å·¥å…·æè¿°**ï¼ˆæ³¨å…¥åˆ°ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰ï¼š

```
<|start_header_id|>user<|end_header_id|>

Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}. Do not use variables.

{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get the current weather for a city",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {
                    "type": "string"
                },
                "unit": {
                    "type": "string",
                    "enum": [
                        "celsius",
                        "fahrenheit"
                    ]
                }
            },
            "required": [
                "city"
            ]
        }
    }
}

What's the weather like in San Francisco?<|eot_id|>
```

### 3. å®Œæ•´ Promptï¼ˆå‘é€ç»™æ¨¡å‹ï¼‰

```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Environment: ipython
Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

You are a helpful assistant with tool calling capabilities. Only reply with a tool call if the function exists in the library provided by the user. If it doesn't exist, just reply directly in natural language. When you receive a tool call response, use the output to format an answer to the original user question.<|eot_id|><|start_header_id|>user<|end_header_id|>

Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}. Do not use variables.

{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get the current weather for a city",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string"},
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
            },
            "required": ["city"]
        }
    }
}

What's the weather like in San Francisco?<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

### 4. æ¨¡å‹è¾“å‡º

```
{"name": "get_weather", "parameters": {"city": "San Francisco", "unit": "celsius"}}
```

### 5. ToolParser è§£æ

**æ–‡ä»¶**: `vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py`

**å…³é”®ä»£ç **ï¼ˆç¬¬ 69-125 è¡Œï¼‰ï¼š

```python
def extract_tool_calls(self, model_output: str, request) -> ExtractedToolCallInformation:
    # å¿«é€Ÿæ£€æŸ¥
    if not (self.bot_token in model_output or "{" in model_output):
        return ExtractedToolCallInformation(
            tools_called=False, tool_calls=[], content=model_output
        )

    # ä½¿ç”¨æ­£åˆ™æŸ¥æ‰¾ JSON å¯¹è±¡
    match = self.tool_call_regex.search(model_output)
    if not match:
        return ExtractedToolCallInformation(
            tools_called=False, tool_calls=[], content=model_output
        )

    try:
        json_str = match.group(0)
        # æ”¯æŒåˆ†å·åˆ†éš”çš„å¤šä¸ª JSON
        json_objects = [obj.strip() for obj in json_str.split(";")]

        tool_calls = []
        for json_obj in json_objects:
            if not json_obj:
                continue
            obj = json.loads(json_obj)
            tool_calls.append(
                ToolCall(
                    type="function",
                    function=FunctionCall(
                        name=obj["name"],
                        arguments=json.dumps(
                            obj["arguments"] if "arguments" in obj else obj["parameters"],
                            ensure_ascii=False
                        )
                    )
                )
            )

        return ExtractedToolCallInformation(
            tools_called=True,
            tool_calls=tool_calls,
            content=None
        )

    except Exception:
        logger.exception("Error in extracting tool call from response.")
        return ExtractedToolCallInformation(
            tools_called=False, tool_calls=[], content=model_output
        )
```

**è§£æç»“æœ**ï¼š

```python
ExtractedToolCallInformation(
    tools_called=True,
    tool_calls=[
        ToolCall(
            type="function",
            function=FunctionCall(
                name="get_weather",
                arguments='{"city":"San Francisco","unit":"celsius"}'
            )
        )
    ],
    content=None
)
```

---

## ä¸¤è€…å¯¹æ¯”

| ç‰¹æ€§ | DeepSeek V3.1 | Llama 3.1 |
|------|--------------|-----------|
| **å·¥å…·æè¿°æ³¨å…¥ä½ç½®** | System Promptï¼ˆç¬¬ 25 è¡Œï¼‰ | ç¬¬ä¸€æ¡ User Messageï¼ˆç¬¬ 77 è¡Œï¼‰ |
| **å·¥å…·å®šä¹‰æ ¼å¼** | Markdown é£æ ¼ï¼ˆ## Tools, ### function_nameï¼‰ | JSON æ ¼å¼ï¼ˆå®Œæ•´ tool schemaï¼‰ |
| **è¾“å‡ºæ ¼å¼** | Special Tokensï¼š`<ï½œtoolâ–callâ–beginï½œ>name<ï½œtoolâ–sepï½œ>args<ï½œtoolâ–callâ–endï½œ>` | Pure JSONï¼š`{"name": "...", "parameters": {...}}` |
| **è§£ææ–¹å¼** | æ­£åˆ™æå– special token åŒ…è£¹çš„å†…å®¹ | æ­£åˆ™æŸ¥æ‰¾ JSON å¯¹è±¡ + JSON è§£æ |
| **å¤šå·¥å…·è°ƒç”¨** | é“¾å¼ï¼š`<ï½œtoolâ–callâ–beginï½œ>...ï½œ><ï½œtoolâ–callâ–beginï½œ>...` | åˆ†å·åˆ†éš”ï¼š`{...}; {...}` |
| **Template æ–‡ä»¶** | `tool_chat_template_deepseekv31.jinja` | `tool_chat_template_llama3.1_json.jinja` |
| **Parser ç±»** | `DeepSeekV31ToolParser` | `Llama3JsonToolParser` |
| **å¯åŠ¨å‚æ•°** | `--tool-call-parser deepseek_v31` | `--tool-call-parser llama3_json` |

---

## æºç è§£æ

### 1. æœåŠ¡å±‚é›†æˆ

**æ–‡ä»¶**: `vllm/entrypoints/openai/serving_engine.py:1094-1108`

```python
# æ£€æŸ¥æ˜¯å¦éœ€è¦è§£æå·¥å…·è°ƒç”¨
should_parse_tools = tool_parser is not None and (
    hasattr(request, "tool_choice") and request.tool_choice != "none"
)

if should_parse_tools:
    if not isinstance(request, ChatCompletionRequest):
        msg = "Tool usage is only supported for Chat Completions API"
        raise NotImplementedError(msg)

    # è°ƒç”¨ ToolParser çš„ adjust_request() æ–¹æ³•
    # DeepSeek V3.1 æ²¡æœ‰é‡å†™æ­¤æ–¹æ³•ï¼Œç›´æ¥è¿”å›åŸè¯·æ±‚
    # æŸäº› parser å¯èƒ½ä¼šä¿®æ”¹è¯·æ±‚ï¼ˆå¦‚æ·»åŠ é¢å¤–çš„ system messageï¼‰
    request = tool_parser(tokenizer).adjust_request(request=request)
```

### 2. Chat Template åº”ç”¨

**æ–‡ä»¶**: `vllm/entrypoints/chat_utils.py:1525-1561`

```python
def apply_hf_chat_template(
    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast,
    conversation: list[ConversationMessage],
    chat_template: str | None,
    tools: list[dict[str, Any]] | None,
    *,
    model_config: ModelConfig,
    **kwargs: Any,
) -> str:
    # è§£æ chat templateï¼ˆå¯èƒ½æ˜¯è‡ªå®šä¹‰çš„ï¼Œä¹Ÿå¯èƒ½æ˜¯ tokenizer è‡ªå¸¦çš„ï¼‰
    hf_chat_template = resolve_hf_chat_template(
        tokenizer,
        chat_template=chat_template,
        tools=tools,
        model_config=model_config,
    )

    if hf_chat_template is None:
        raise ValueError("Chat template is required")

    # è§£ææ¨¡æ¿ä¸­ä½¿ç”¨çš„å˜é‡
    resolved_kwargs = resolve_chat_template_kwargs(
        tokenizer=tokenizer,
        chat_template=hf_chat_template,
        chat_template_kwargs=kwargs,
    )

    # è°ƒç”¨ tokenizer çš„ apply_chat_template
    # tools å‚æ•°ä¼šè¢«ä¼ å…¥ Jinja2 æ¨¡æ¿ä¸­
    return tokenizer.apply_chat_template(
        conversation=conversation,
        tools=tools,  # â† å…³é”®ï¼šä¼ å…¥ tools
        chat_template=hf_chat_template,
        tokenize=False,
        **resolved_kwargs,
    )
```

### 3. è¾“å‡ºè§£æï¼ˆæµå¼ï¼‰

**æ–‡ä»¶**: `vllm/entrypoints/openai/serving_chat.py:974-988`

```python
# åœ¨æµå¼è¾“å‡ºçš„æ¯ä¸ª chunk ä¸­è°ƒç”¨
if tool_parser:
    delta_message = tool_parser.extract_tool_calls_streaming(
        previous_text=previous_text,
        current_text=current_text,
        delta_text=delta_text,
        previous_token_ids=previous_token_ids,
        current_token_ids=current_token_ids,
        delta_token_ids=delta_token_ids,
        request=request,
    )

    # delta_message å¯èƒ½åŒ…å«ï¼š
    # - content: æ™®é€šæ–‡æœ¬
    # - tool_calls: å·¥å…·è°ƒç”¨çš„å¢é‡æ›´æ–°
    #   - index: å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼ˆæ”¯æŒå¤šä¸ªå·¥å…·ï¼‰
    #   - function.name: é¦–æ¬¡å‡ºç°æ—¶å‘é€
    #   - function.arguments: å¢é‡å‘é€ï¼ˆå¦‚ "{\"city\"" -> ":\"Beijing\"}")
```

### 4. ToolParser æ³¨å†Œæœºåˆ¶

**æ–‡ä»¶**: `vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py:86-155`

```python
class ToolParserManager:
    tool_parsers: dict[str, type] = {}

    @classmethod
    def register_module(cls, name: str | list[str] | None = None, ...):
        """è£…é¥°å™¨ï¼Œç”¨äºæ³¨å†Œ ToolParser"""
        def _register(module):
            cls._register_module(module=module, module_name=name, ...)
            return module
        return _register

    @classmethod
    def get_tool_parser(cls, name) -> type:
        """æ ¹æ®åç§°è·å– ToolParser ç±»"""
        if name in cls.tool_parsers:
            return cls.tool_parsers[name]
        raise KeyError(f"tool helper: '{name}' not found")
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# åœ¨ deepseekv31_tool_parser.py ä¸­
@ToolParserManager.register_module("deepseek_v31")
class DeepSeekV31ToolParser(ToolParser):
    ...

# åœ¨ llama_tool_parser.py ä¸­
@ToolParserManager.register_module("llama3_json")
@ToolParserManager.register_module("llama4_json")
class Llama3JsonToolParser(ToolParser):
    ...
```

---

## å®æˆ˜æŒ‡å—

### å¯åŠ¨ vLLM æœåŠ¡å™¨

#### DeepSeek V3.1

```bash
vllm serve deepseek-ai/DeepSeek-V3.1 \
  --enable-auto-tool-choice \
  --tool-call-parser deepseek_v31 \
  --chat-template examples/tool_chat_template_deepseekv31.jinja
```

#### Llama 3.1

```bash
vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct \
  --enable-auto-tool-choice \
  --tool-call-parser llama3_json \
  --chat-template examples/tool_chat_template_llama3.1_json.jinja
```

### å‘é€è¯·æ±‚

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="EMPTY"
)

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get weather info",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string"}
                },
                "required": ["city"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V3.1",
    messages=[
        {"role": "user", "content": "What's the weather in Beijing?"}
    ],
    tools=tools,
    tool_choice="auto"
)

# å¤„ç†å·¥å…·è°ƒç”¨
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        print(f"Tool: {tool_call.function.name}")
        print(f"Args: {tool_call.function.arguments}")
```

### å¤šè½®å¯¹è¯ï¼ˆå·¥å…·è°ƒç”¨ + å·¥å…·è¾“å‡º + æœ€ç»ˆå›ç­”ï¼‰

```python
# ç¬¬ä¸€è½®ï¼šç”¨æˆ·è¯·æ±‚
messages = [
    {"role": "user", "content": "What's the weather in Tokyo?"}
]

response1 = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V3.1",
    messages=messages,
    tools=tools
)

# æå–å·¥å…·è°ƒç”¨
tool_call = response1.choices[0].message.tool_calls[0]
messages.append(response1.choices[0].message)

# ç¬¬äºŒè½®ï¼šè¿”å›å·¥å…·æ‰§è¡Œç»“æœ
messages.append({
    "role": "tool",
    "tool_call_id": tool_call.id,
    "content": '{"temperature": 18, "condition": "sunny"}'
})

# ç¬¬ä¸‰è½®ï¼šè·å–æœ€ç»ˆå›ç­”
response2 = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V3.1",
    messages=messages,
    tools=tools
)

print(response2.choices[0].message.content)
# è¾“å‡º: "The weather in Tokyo is currently sunny with a temperature of 18Â°C."
```

### è‡ªå®šä¹‰ ToolParser

å¦‚æœä½ æƒ³ä¸ºè‡ªå·±çš„æ¨¡å‹å®ç° tool callingï¼Œéœ€è¦ï¼š

1. **åˆ›å»ºè‡ªå®šä¹‰ chat template**ï¼ˆ`.jinja` æ–‡ä»¶ï¼‰
2. **å®ç° ToolParser å­ç±»**
3. **æ³¨å†Œ ToolParser**

**ç¤ºä¾‹**ï¼š

```python
# my_tool_parser.py
import regex as re
from vllm.entrypoints.openai.tool_parsers import (
    ToolParser, ToolParserManager
)

@ToolParserManager.register_module("my_custom_parser")
class MyCustomToolParser(ToolParser):
    def __init__(self, tokenizer):
        super().__init__(tokenizer)
        # å®šä¹‰ä½ çš„ special tokens
        self.tool_start = "<|tool|>"
        self.tool_end = "<|/tool|>"
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼
        self.regex = re.compile(r"<\|tool\|>(.*?)<\|/tool\|>", re.DOTALL)

    def extract_tool_calls(self, model_output, request):
        # å®ç°è§£æé€»è¾‘
        matches = self.regex.findall(model_output)
        # ... å¤„ç†å¹¶è¿”å› ExtractedToolCallInformation

    def extract_tool_calls_streaming(self, ...):
        # å®ç°æµå¼è§£æé€»è¾‘
        # ... è¿”å› DeltaMessage
```

**å¯åŠ¨æ—¶æŒ‡å®š**ï¼š

```bash
vllm serve my-model \
  --enable-auto-tool-choice \
  --tool-call-parser my_custom_parser \
  --tool-parser-plugin /path/to/my_tool_parser.py \
  --chat-template /path/to/my_template.jinja
```

---

## æ€»ç»“

### å…³é”®è¦ç‚¹

1. âœ… **vLLM é€šè¿‡è‡ªå®šä¹‰ chat template æ³¨å…¥å·¥å…·æè¿°**ï¼Œè€Œä¸æ˜¯ä¾èµ–æ¨¡å‹åŸç”Ÿ tokenizer çš„æ¨¡æ¿
2. âœ… **ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„è¾“å‡ºæ ¼å¼**ï¼š
   - DeepSeekï¼šSpecial Tokensï¼ˆ`<ï½œtoolâ–callâ–beginï½œ>...`ï¼‰
   - Llamaï¼šPure JSONï¼ˆ`{"name": "...", "parameters": {...}}`ï¼‰
3. âœ… **ToolParser è´Ÿè´£è§£ææ¨¡å‹è¾“å‡º**ï¼Œæå–ç»“æ„åŒ–çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
4. âœ… **å®Œå…¨å…¼å®¹ OpenAI API**ï¼Œå®¢æˆ·ç«¯æ— éœ€æ„ŸçŸ¥åº•å±‚å®ç°å·®å¼‚

### æ ¸å¿ƒæµç¨‹å›é¡¾

```
ç”¨æˆ· tools â†’ Chat Template æ³¨å…¥ â†’ æ¨¡å‹è¾“å‡º â†’ ToolParser è§£æ â†’ OpenAI æ ¼å¼è¿”å›
```

### å‚è€ƒèµ„æ–™

- vLLM å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.vllm.ai/en/stable/features/tool_calling.html
- æºç ä»“åº“ï¼šhttps://github.com/vllm-project/vllm
- DeepSeek V3.1 Templateï¼š`examples/tool_chat_template_deepseekv31.jinja`
- Llama 3.1 Templateï¼š`examples/tool_chat_template_llama3.1_json.jinja`
- ToolParser å®ç°ï¼š`vllm/entrypoints/openai/tool_parsers/`

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2025-01-21
**vLLM ç‰ˆæœ¬**: Based on latest main branch
**ä½œè€…**: Claude Code Analysis
