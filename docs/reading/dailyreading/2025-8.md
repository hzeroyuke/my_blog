## 8.1

- [[2507.21892] Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning](https://arxiv.org/abs/2507.21892)
    - 一篇基于在Graph Rag上做强化学习，提高问答质量的工作
    - 但是个人觉得没有解决需要高质量的Rag图的问题，只是增强模型在Graph rag上探索的能力
- [TestSprite - Homepage](https://www.testsprite.com/)
    - AI for software testing

## 8.5

- [[2507.21509] Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)
    - 人格向量来控制LLM的情绪，对于人格or情绪模拟技术有价值
- [[2508.00819] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
    - Diffusion LLM的一种动态调整生成长度的方案，通过计算最后一个token生成EOS的置信度，来判断是否要调整生成长度
- [https://n8nchat.com/](https://n8nchat.com/)
    - n8n的AI辅助工具，用来快速地查询节点功能和参数

## 8.7

- [https://arxiv.org/abs/2508.03680](https://arxiv.org/abs/2508.03680)
    - 微软开发的一个agent训练框架，将agent执行和训练解耦开，可以在几乎不影响原有agent代码的情况下对于agent进行训练，因此也天然适配LangChain等大量agent框架，其自称是Any Framework
- [[2508.02193] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference](https://www.arxiv.org/abs/2508.02193)
    - 字节开发的Diffusion LLM，目标侧重代码生成，以及生成的速度提升

## 8.8

- [https://github.com/google/langextract](https://github.com/google/langextract)
    - 这是Google开发的一个用于做文本信息提取的，从大规模文本中提取结构化数据，开源，其效果类似一个完整的Rag产品
- [[2508.04604v1] TURA: Tool-Augmented Unified Retrieval Agent for AI Search](https://arxiv.org/abs/2508.04604v1)
    - 关于Tool Search的一个解决方案，较为复杂
- [[2508.03923] CoAct-1: Computer-using Agents with Coding as Actions](https://arxiv.org/abs/2508.03923)
    - 关于Computer-use，除了GUI方案之外还做了编程工具，会将任务分配导代码agent和GUI agent上，更好地实现Browser use
- [[2508.03012] Tool-integrated Reinforcement Learning for Repo Deep Search](https://www.arxiv.org/abs/2508.03012)
    - 字节的一篇关于代码库问题定位的工作，用了微调和RL，并且提供了一个数据集，是来自Github仓库+Issues，随后是人工筛选之后的结果
    - 拒绝采样微调：是指在模型上做某个任务，去掉其中失败的轨迹，使用成功的次数进行微调的方案

## 8.12

- [[2508.05629] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
    - DFT，动态调整SFT的梯度反馈，使其可以达到RL的泛化性

## 8.14

- [[2508.08221] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://www.arxiv.org/abs/2508.08221)
    - 关于RL的各种config做了很多的消融实验，一篇比较好的综述来判断如何在RL中选择合适的配置

## 8.22

- [[2508.14704] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers](https://arxiv.org/abs/2508.14704)
    - 关于LLM使用MCP的一个Benchmark，设计了十几个不同领域的MCP，观察LLM调用的能力