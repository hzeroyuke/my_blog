## 9.1

- [[2508.21038] On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
    - Google的一篇关于单向量rag的理论分析，表明了单向量的embedding检索是存在理论上限的
- [科普向：一文解构大模型后训练，GRPO和它的继任者们的前世今生](https://mp.weixin.qq.com/s/JjP6a9htmtdRDfMtyBaIGQ)
    - GRPO的后继者的简单总结

## 9.22

- [[2509.13311] Towards General Agentic Intelligence via Environment Scaling](https://www.arxiv.org/abs/2509.13311)
    - 构建一个可扩展的环境，算是ToolBench那个工具集的扩充版本
- [[2509.13310] Scaling Agents via Continual Pre-training](https://www.arxiv.org/abs/2509.13310)
    - 将Agent能力作为预训练的一部分
- [[2509.15207] FlowRL: Matching Reward Distributions for LLM Reasoning](https://www.arxiv.org/abs/2509.15207)
    - 基于Flow的范式，修改奖励的获取，相比于最大化奖励应该更加拟合奖励的分布，最重要是鼓励生成的多样性，而不是坍缩到一个点

## 9.23

下面这段节选自苹果的一篇多模态大模型的论文，介绍了现阶段主流的MLLM的形式

1. **纯理解型多模态LLM（MLLMs for Image Understanding）**
    
    - 典型架构：冻结视觉编码器 + 轻量连接器 + 大语言模型
        - Flamingo（交叉注意力注入）
        - BLIP-2（Q-Former对齐）
        - LLaVA、MM1、InternVL、Qwen-VL 系列（MLP 投影，规模化数据与模型）
    - 共同局限：仅支持图像→文本理解，不具备原生图像生成能力。

2. **统一多模态模型（Unified Multimodal Models）** 按架构范式细分三类：
    
    - **统一自回归（AR）**将图像转为离散/连续 token 序列，与文本一起自回归建模。代表：Chameleon、Emu3、Janus、Bagel、X-Omni 等。
    - **冻结 LLM + 外接扩散解码器（Decoupled LLM-Diffusion）**LLM 仅负责语义，生成交给独立扩散模型。代表：Qwen-Image、OmniGen2、MetaQuery 等。
    - **混合 AR-扩散（Hybrid AR-Diffusion）**在同一 Transformer 内交替执行 next-token 预测与扩散去噪。代表：Transfusion、TRIM 等。
    
    Manzano 与第一类最相近，但关键区别是提出**单一视觉编码器 + 双轻量适配器**的混合 tokenizer，避免异构 token 同仓输入，缓解任务冲突。
    
3. **扩散式图像生成模型（Diffusion Models for Image Generation）**
    
    - 基础：DDPM、Score-SDE
    - 潜空间加速：LDM / Stable Diffusion 系列
    - 流匹配（Flow-Matching）与 DiT 架构：PixArt-α、SD3、Flux、DiT-Air 等Manzano 的图像解码器即采用**潜空间 Flow-Matching + DiT-Air**，并以 LLM 输出的离散视觉 token 作为条件，而非传统文本编码器。

- [[2509.16127] BaseReward: A Strong Baseline for Multimodal Reward Model](https://arxiv.org/abs/2509.16127)
    - 统一的较大的reward model
- [[2509.16197] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
    - 苹果最新的MLLM，里面有一些较新的综述