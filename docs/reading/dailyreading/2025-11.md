## 11.11

- https://arxiv.org/abs/2511.05271
	- DeepEyes：类似于ReTool的增强版，增加了code，search工具以及模型原生的多模态能力，做SFT+RL
	- 开源了SFT和RL data
- https://arxiv.org/abs/2511.04662
	- VeriCot：做过程监督，主要目标是监督Cot，目前的监督方案往往只监督结果，但是面对Cot中的出现的错误逻辑视而不见，其将Cot的自然语言翻译成SMT-LIB一阶逻辑公式，来做形式化的验证
	- 这个将Cot翻译成逻辑公式的过程是LLM做的
- https://arxiv.org/abs/2511.03506
	- HaluMem：一个benchmark，用于评估一个Memory系统的幻觉率

## 11.12

- https://arxiv.org/abs/2511.06221
	- VibeThinker：小模型能否激发出超过千亿级别的大模型的推理能力，这个真是语言模型了，1.5B的小模型，在AIME等多个benchmark上超过了R1
	- 激发推理能力，在SFT阶段鼓励探索是关键

## 11.13

- https://relieved-cafe-fe1.notion.site/JustRL-Scaling-a-1-5B-LLM-with-a-Simple-RL-Recipe-24f6198b0b6b80e48e74f519bfdaf0a8 
	- JustRL：展现了在简单配置下RL能够达到的上限，对比可以判断一些特殊的技巧是否真的提高了上限，而不是baseline做的不够充分
![](asset/Pasted%20image%2020251113230546.png)

个人认为最重要是熵的正常上下波动，没有探索崩溃或者过早收敛，其在消融实验中表示，常见的回复过长的抑制，反而是使得Entropy的可能原因之一

但是这个论文没有经过充分的实验的对比，以及在不同尺寸，不同基座的模型，不同场景的进行训练的结果，仅仅是在一个场景，未必能够得到普适的结论

- https://arxiv.org/abs/2511.08923
	- TiDar：用扩散模型进行起草，然后用AR来输出结果（组织语言），第一个将Dllm的输出质量拉到和AR模型同一水平线的
- https://arxiv.org/abs/2511.08633
	- Time to Move：可控视频生成，单靠文本+初始帧无法做到有效的可控视频生成，因此本文提出了一个新的方案（没有完全看懂）

## 11.18

- https://arxiv.org/abs/2511.09146
	- Dope 一种新的位置编码方式，一种无需训练的方式，可以即插即用，具体的实现还没理解清楚
- https://arxiv.org/abs/2511.11434
	- WEAVE benchmark，针对于同一生成理解的多模态大模型的benchmark，侧重于多轮对话
- https://arxiv.org/abs/2511.11062
	- LiteAttention 一种针对于Dit的Flash Attention的改进机制，主要针对于时评生成
- https://arxiv.org/abs/2511.09611
	- MMaDA-Parallel 多模态的Dllm，此次又做了一个新的bench，来体现自回归范式中比较严重的错误累积问题


## 11.19

- https://arxiv.org/abs/2511.10555
	- CoTyle 生成的风格控制，在文生图这个领域要做风格控制往往要做很复杂的提示词工程，难度高且浪费资源
	- 在CoTyle的范式中，使用一个数字来做风格化的控制，训练了一个Style Codebook，来将数字转换成风格嵌入，将这个嵌入和文本嵌入一起训练生成模型
- https://arxiv.org/abs/2511.14582
	- OmniZip：目标是在Omni模型中有效地压缩音频+视频Token
	- 音频+视频联动地进行剪枝
![](asset/Pasted%20image%2020251119151311.png)

## 11.26

- https://arxiv.org/abs/2511.19428v1
	- Flow-Map，对于Flow Model做蒸馏的时候，不需要显式的数据，而是根据教师模型在某一点的ode速度进行蒸馏，因此这是一种data free的方案


