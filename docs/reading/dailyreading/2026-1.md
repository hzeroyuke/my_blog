
## 1.1

- Video Models are Zero-Shot reasoner and learner
	- Google Veo3 的论文，展示了Veo3在经过大规模训练之后涌现出来的Zero shot的能力，能够完成训练数据以外的各种任务，展现了惊人的涌现能力

## 1.2

- mHC https://arxiv.org/abs/2512.24880
	- DeepSeek的论文，对于残差流进行了修改，将恒定为1的残差流转换成一个可学习的目标，并且将其进行Manifold-Constrained防止残差流变得过大
- Evaluating Parameter Efficient Methods for RLVR
	- 对于RLVR任务中高效参数微调方案的一个分析实验，包括Lora，DoRA、AdaLoRA等变体

## 1.4

- [JavisGPT](https://www.arxiv.org/abs/2512.22905) 
	- 音视频编辑的模型，通过一个QwenVL+Dit拼接的架构，完成了多模态的理解和生成，包括编辑，并且着重优化了音视频协同的内容
	- 输入包括video的输入，音频的输入，文本提示词。基于QwenVL，然后适配了一个Lora来进行微调。最后LLM会将输出给一个Dit，让其输出编辑好的视频音频内容

![](asset/867cc7bd6b4de1c08fdf03f03ecb0935.png)

生成和理解是否需要纳入在统一的框架中，现有的方案似乎仍然没有指出一条明确的路径。从nano-banana的角度来看，似乎目前最好的方案还是让生成理解进行分离，作为一个系统进行处理

- https://arxiv.org/pdf/2512.24873 Agent Learning EcoSystem
	- 是阿里团队做一个完整且系统的Agent学习框架，将阿里之前做的很多Agent相关的工作串了起来，并且致力于解决训推不一致，力图构建足够Strong的Agent RL baseline
	- ROLL：支持异步 rollout-训练解耦、动态 GPU 分时复用、chunk 级信用分配的 RL 训练框架。训练框架
	- ROCK：万级并发、安全隔离、GEM API 兼容的沙箱环境引擎，实现轨迹采集与运行时验证。核心是沙盒
	- iFlow CLI：统一上下文管理、可配置工作流的代理框架，保证“训练-部署”零差异。核心是上下文管理

![](asset/Pasted%20image%2020260104183643.png)

- [Recursive Language Model](https://arxiv.org/pdf/2512.24601v1)
	- 这篇论文主要针对的是超长上下文的问题，其让LLM将上下文作为一个环境变量去处理，而不是每次都一股脑地把所有上下文都塞进模型中
	- 让模型自己编写Python代码来拆解上下文和调用自己，来实现上下文的高效处理

![](asset/Pasted%20image%2020260104190459.png)